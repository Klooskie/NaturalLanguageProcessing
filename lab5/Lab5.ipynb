{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../lab1/ustawy/1993_599.txt',\n",
       " '../lab1/ustawy/1993_602.txt',\n",
       " '../lab1/ustawy/1993_645.txt',\n",
       " '../lab1/ustawy/1993_646.txt',\n",
       " '../lab1/ustawy/1994_150.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../lab1/ustawy/'\n",
    "file_names = sorted(glob.glob(PATH + \"*\"))\n",
    "file_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "law_acts =[]\n",
    "for file_name in file_names:\n",
    "    with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "        law_acts.append(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 2\n",
    "Znalezienie tokenów z korpusu w postaci tupli (lemat (downcased), kategoria morfosyntaktyczna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21 s, sys: 1.62 s, total: 22.6 s\n",
      "Wall time: 1h 31min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokens_per_act = []\n",
    "\n",
    "for law_act in law_acts:\n",
    "    tokens = []\n",
    "    response_lines = requests.post('http://localhost:9200', law_act.encode('utf-8')).content.decode('utf-8').split('\\n')\n",
    "    for line in response_lines:\n",
    "        line_words = line.split('\\t')\n",
    "        if line_words[0] == '' and len(line_words) >= 2:\n",
    "            tokens.append((line_words[1].lower().strip(), line_words[2].split(':')[0]))\n",
    "    tokens_per_act.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dziennik', 'brev'),\n",
       " ('.', 'interp'),\n",
       " ('ustawa', 'brev'),\n",
       " ('.', 'interp'),\n",
       " ('z', 'prep'),\n",
       " ('1993', 'adj'),\n",
       " ('rok', 'brev'),\n",
       " ('.', 'interp'),\n",
       " ('numer', 'brev'),\n",
       " ('129', 'num')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_per_act[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 3\n",
    "Obliczenie licznika bigramów powstałych z opisanych wyżej tokenów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.67 s, sys: 19.4 ms, total: 5.69 s\n",
      "Wall time: 5.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bigrams_counter = {}\n",
    "for tokens in tokens_per_act:\n",
    "    bigrams = zip(tokens[:-1], tokens[1:])\n",
    "    for bigram in bigrams:\n",
    "        bigrams_counter[bigram] = bigrams_counter.get(bigram, 0) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 4\n",
    "Odfiltrowanie bigramów zawierających nie litery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 355 ms, sys: 16.1 ms, total: 371 ms\n",
      "Wall time: 368 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_bigrams_counter = {}\n",
    "for bigram, count in bigrams_counter.items():\n",
    "    if bigram[0][0].isalpha() and bigram[1][0].isalpha():\n",
    "        new_bigrams_counter[bigram] = count\n",
    "bigrams_counter = new_bigrams_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 6\n",
    "Obliczenie LLR dla znalezionych bigramów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2768350"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_number_of_bigrams = sum(list(bigrams_counter.values()))\n",
    "total_number_of_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute counter of bigrams starting with a\n",
    "bigrams_starting_with_a_counter = {}\n",
    "for bigram, count in bigrams_counter.items():\n",
    "    a = bigram[0]\n",
    "    bigrams_starting_with_a_counter[a] = bigrams_starting_with_a_counter.get(a, 0) + count\n",
    "    \n",
    "# compute counter of bigrams ending with b\n",
    "bigrams_ending_with_b_counter = {}\n",
    "for bigram, count in bigrams_counter.items():\n",
    "    b = bigram[1]\n",
    "    bigrams_ending_with_b_counter[b] = bigrams_ending_with_b_counter.get(b, 0) + count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H(k):\n",
    "    N = np.sum(k)\n",
    "    return np.sum(k/N * np.log(k/N + (k==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.8 s, sys: 523 ms, total: 47.3 s\n",
      "Wall time: 47.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bigrams_llr = {}\n",
    "for bigram, count in bigrams_counter.items():\n",
    "    a, b = bigram\n",
    "    a_and_b = count\n",
    "    a_without_b = bigrams_starting_with_a_counter[a] - a_and_b\n",
    "    b_but_not_a = bigrams_ending_with_b_counter[b] - a_and_b\n",
    "    neither_a_nor_b = total_number_of_bigrams - bigrams_starting_with_a_counter[a] \\\n",
    "        - bigrams_ending_with_b_counter[b] + a_and_b\n",
    "    \n",
    "    k = np.array([[a_and_b, b_but_not_a], [a_without_b, neither_a_nor_b]])\n",
    "    row_sums = np.array([a_and_b + b_but_not_a, a_without_b + neither_a_nor_b])\n",
    "    col_sums = np.array([a_and_b + a_without_b, b_but_not_a + neither_a_nor_b])\n",
    "    llr = 2 * np.sum(k) * (H(k) - H(row_sums) - H(col_sums))\n",
    "    bigrams_llr[bigram] = llr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((('ustawa', 'subst'), ('z', 'prep')), 42102.727935503),\n",
       " ((('z', 'prep'), ('dzień', 'subst')), 53719.90512407017),\n",
       " ((('o', 'prep'), ('zmiana', 'subst')), 4524.518585883802),\n",
       " ((('zmiana', 'subst'), ('ustawa', 'subst')), 4469.472597983152),\n",
       " ((('ustawa', 'subst'), ('o', 'prep')), 4768.254868144018),\n",
       " ((('o', 'prep'), ('podatek', 'subst')), 1650.9791429647435),\n",
       " ((('podatek', 'subst'), ('od', 'prep')), 2545.2504767769183),\n",
       " ((('od', 'prep'), ('towar', 'subst')), 933.3632228124396),\n",
       " ((('towar', 'subst'), ('i', 'conj')), 1675.4625112097674),\n",
       " ((('i', 'conj'), ('usługa', 'subst')), 1884.330998092189)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bigrams_llr.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 7\n",
    "Wyznaczenie partycji bigramów zawierających tokeny z tymi samymi kategoriami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions = {}\n",
    "partitions_size = {}\n",
    "\n",
    "for bigram, count in bigrams_counter.items():\n",
    "    partition = (bigram[0][1], bigram[1][1])\n",
    "    partitions[partition] = partitions.get(partition, []) + [(bigram[0][0], bigram[1][0])]\n",
    "    partitions_size[partition] = partitions_size.get(partition, 0) + count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 8\n",
    "Wyznaczenie 10 najliczniejszych partycji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('prep', 'subst'), 327841),\n",
       " (('subst', 'subst'), 293793),\n",
       " (('subst', 'adj'), 274962),\n",
       " (('adj', 'subst'), 188439),\n",
       " (('subst', 'prep'), 173782),\n",
       " (('subst', 'conj'), 85165),\n",
       " (('conj', 'subst'), 84274),\n",
       " (('prep', 'adj'), 79485),\n",
       " (('ger', 'subst'), 76538),\n",
       " (('prep', 'brev'), 67137)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largest_partitions = sorted(list(partitions_size.items()), key=(lambda x: (-x[1], x[0])))[:10]\n",
    "largest_partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 9\n",
    "Wyznaczenie 5 bigramów z najwyższym LLR reprezentujących każdą z partycji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "categories_representatives = {}\n",
    "sorted_bigrams = sorted(list(bigrams_llr.items()), key=(lambda x: (-x[1], x[0])))\n",
    "for partition, size in largest_partitions:\n",
    "    representatives_found = 0\n",
    "    for bigram, llr in sorted_bigrams:\n",
    "        if bigram[0][1] == partition[0] and bigram[1][1] == partition[1]:\n",
    "            categories_representatives[partition] = categories_representatives.get(partition, []) + [((bigram[0][0], bigram[1][0]), llr)]\n",
    "            representatives_found += 1\n",
    "            if representatives_found == 5:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition: ('prep', 'subst')\n",
      "Representatives:\n",
      "(('z', 'dzień'), 53719.90512407017)\n",
      "(('na', 'podstawa'), 47389.81442574456)\n",
      "(('do', 'sprawa'), 46331.317170673115)\n",
      "(('w', 'droga'), 32059.638214459912)\n",
      "(('od', 'dzień'), 31767.932084897366)\n",
      "\n",
      "Partition: ('subst', 'subst')\n",
      "Representatives:\n",
      "(('droga', 'rozporządzenie'), 53978.44612045842)\n",
      "(('skarb', 'państwo'), 21933.48773133111)\n",
      "(('rada', 'minister'), 18342.06970079752)\n",
      "(('terytorium', 'rzeczpospolita'), 14155.022492691465)\n",
      "(('ochrona', 'środowisko'), 14029.946469116026)\n",
      "\n",
      "Partition: ('subst', 'adj')\n",
      "Representatives:\n",
      "(('minister', 'właściwy'), 71029.07051601577)\n",
      "(('rzeczpospolita', 'polski'), 41742.7716811986)\n",
      "(('jednostka', 'organizacyjny'), 24609.374292130935)\n",
      "(('samorząd', 'terytorialny'), 23394.1293598482)\n",
      "(('produkt', 'leczniczy'), 21913.360666442946)\n",
      "\n",
      "Partition: ('adj', 'subst')\n",
      "Representatives:\n",
      "(('który', 'mowa'), 249005.7458068642)\n",
      "(('niniejszy', 'ustawa'), 21509.338101544676)\n",
      "(('następujący', 'zmiana'), 18174.091280081757)\n",
      "(('odrębny', 'przepis'), 13058.805740462481)\n",
      "(('walny', 'zgromadzenie'), 9635.448067530886)\n",
      "\n",
      "Partition: ('subst', 'prep')\n",
      "Representatives:\n",
      "(('mowa', 'w'), 177761.77727743043)\n",
      "(('ustawa', 'z'), 42102.727935503)\n",
      "(('wniosek', 'o'), 16433.817308712587)\n",
      "(('dzień', 'od'), 13931.849752685646)\n",
      "(('miesiąc', 'od'), 12378.659493891777)\n",
      "\n",
      "Partition: ('subst', 'conj')\n",
      "Representatives:\n",
      "(('przecinek', 'i'), 3967.310028553094)\n",
      "(('imię', 'i'), 2292.3097015813687)\n",
      "(('wolność', 'albo'), 2266.94026814221)\n",
      "(('całość', 'lub'), 2188.904113182431)\n",
      "(('zasada', 'i'), 1918.9313421224795)\n",
      "\n",
      "Partition: ('conj', 'subst')\n",
      "Representatives:\n",
      "(('i', 'tryb'), 4697.863582008701)\n",
      "(('i', 'nazwisko'), 2620.4072799398887)\n",
      "(('i', 'usługa'), 1884.330998092189)\n",
      "(('i', 'adres'), 1756.620436968727)\n",
      "(('i', 'wychowanie'), 1463.0926571964972)\n",
      "\n",
      "Partition: ('prep', 'adj')\n",
      "Representatives:\n",
      "(('o', 'który'), 191025.1762959935)\n",
      "(('za', 'każdy'), 1363.9706171610878)\n",
      "(('w', 'ten'), 1295.1396188301223)\n",
      "(('w', 'właściwy'), 1289.8370749077928)\n",
      "(('przez', 'ten'), 1024.6517498282788)\n",
      "\n",
      "Partition: ('ger', 'subst')\n",
      "Representatives:\n",
      "(('zasięgnąć', 'opinia'), 11526.522059243283)\n",
      "(('pozbawić', 'wolność'), 11328.705238634402)\n",
      "(('wykonywać', 'zawód'), 5572.863391466673)\n",
      "(('zawrzeć', 'umowa'), 5214.00885792127)\n",
      "(('wszcząć', 'postępowanie'), 5123.099072444362)\n",
      "\n",
      "Partition: ('prep', 'brev')\n",
      "Representatives:\n",
      "(('w', 'artykuł'), 114320.77819801666)\n",
      "(('w', 'ustęp'), 88422.20964241368)\n",
      "(('w', 'punkt'), 10945.444949647499)\n",
      "(('z', 'późniejszy'), 7667.805189615354)\n",
      "(('w', 'dziennik'), 4721.440330030875)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for partition, representatives in categories_representatives.items():\n",
    "    print('Partition:', partition)\n",
    "    print('Representatives:')\n",
    "    for r in representatives:\n",
    "        print(r)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wnioski\n",
    "\n",
    "1. What types of bigrams have been found?\n",
    "\n",
    "(Poniżej będę używał nazw części mowy, a nie tagów morfoskładniowych, które im odpowiadają)\n",
    "Dla najliczniejszej partycji bigramów (przyimek+rzeczownik) znaleziono popularne kolokacje np. 'na podstawie', 'w drodze/gę' występujące często w języku normalnie. Dwa rzeczowniki to popularne dwuczłonowe nazwy np. 'rada ministrów', 'skarb państwa'. Analogicznie dwuczłonowe nazwy są też reprezentowane przez rzeczownik+przymiotnik np. 'Rzeczpospolita Polska', 'samorząd terytorialny. Przymiotnik+rzeczownik to często występujące w korpusie połączenia np. 'następująca zmiana', 'walne zgromadzenie', ale nie są to typowe konstrukcje językowe jak przyimek+rzeczownik. Rzeczownik+przyimek bardzo podobnie jak przymiotnik+rzeczownik - bigramy częste w korpusie, nie tak częste ogólnie np. 'mowa w', 'ustawa z'. Bigramy składające się z rzeczownika+spójnika większości nie wydają się reprezentować sobą nic ciekawego, jedynie 'imię i' prawdopodobnie pochodzi z popularnej frazy 'imię i nazwisko'. Podobnie bigramy spójnik+rzeczownik nie wydają się mieć głębszego znaczenia (oprócz 'i nazwisko' podobnie jak 'imię i'). Przyimek+przymiotnik to ta sama kategoria jak przymiotnik+rzeczownik - popularne w korpusie, występujące w języku, ale nie są to typowe konstrukcje językowe, np. 'o którym', 'za każdym'. Rzeczownik odsłowny+rzeczownik to popularne połączenia słów, które nie występują super często (przynajmniej jedno ze słów), ale jak już wystąpią to zazwyczaj są częścią bigramu np. 'zasięgnąć opinii', 'pozbawić wolności'. Ostatnia kategoria składa się cała z określeń miejsca/części artykułu/czasu, np 'w artykule', 'w punkcie'.\n",
    "\n",
    "2. Which of the category-pairs indicate valuable multiword expressions? Do they have anything in common?\n",
    "\n",
    "Większość partycji jest reprezentowana przez wartościowe bigramy. Na szczególną uwagę zasługują na pewno:\n",
    "\n",
    "- przyimek+rzeczownik - są najpopularniejsze i najbardziej przekładają się na cały język\n",
    "\n",
    "- rzeczownik+rzeczownik, rzeczownik+przymiotnik, rzeczownik odsłowny+rzeczownik - reprezentują głównie dwuczłonowe nazwy, albo bigramy których słowa (albo przynajmniej 1 z nich) rzadko występują osobno\n",
    "\n",
    "- przymiotnik+rzeczownik, rzeczownik+przyimek i przyimek+przymiotnik - reprezentują bigramy popularne w korpusie i specyficzne dla niego (nie aż tak popularne ogólnie)\n",
    "\n",
    "3. Which signal: LLR score or syntactic category is more useful for determining genuine multiword expressions?\n",
    "\n",
    "Samo zastosowanie LLR zwróci nam dobre bigramy z punktu widzenia częstości ich występowania (tutaj np. 'ustawa z', 'z dnia'). Nie są one w żaden sposób opisane, czy zaklasyfikowane. Użycie kategorii syntaktycznych po pierwsze pozwala łatwiej zrozumieć co reprezentują sobą bigramy (np. przez analizę partycji), po drugie umożliwia odfiltrowanie często występujących typowych językowych struktów i skupienie się np. na dwuczłonowych nazwach, czy typowych multiwordach dla korpusu. Obie metody mają swoje zastosowanie, ale dla przeciętnego użytkownika prawdopodobnie najlepsze będzie zastosowanie połączenia obu (jak w zadaniu 9)\n",
    "\n",
    "4. Can you describe a different use-case where the morphosyntactic category is useful for resolving a real-world problem?\n",
    "\n",
    "Tagowanie morfoskładniowe mogłoby być użyte np. w procesie automatycznego tłumaczenia tekstu. Typowe struktury zdań mogłyby być opisywane przez gramatykę składającą się z symboli reprezentujących tagi morfoskładniowe. Innym potencjalnym zastosowaniem mogłaby być autokorekta błędnych końcówek słów, w języku polskim bardzo łatwo przekręcając końcówkę zmienić część mowy, np. Polska i polski.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
