{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../lab1/ustawy/1993_599.txt',\n",
       " '../lab1/ustawy/1993_602.txt',\n",
       " '../lab1/ustawy/1993_645.txt',\n",
       " '../lab1/ustawy/1993_646.txt',\n",
       " '../lab1/ustawy/1994_150.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../lab1/ustawy/'\n",
    "file_names = sorted(glob.glob(PATH + \"*\"))\n",
    "file_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "law_acts =[]\n",
    "for file_name in file_names:\n",
    "    with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "        law_acts.append(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 2\n",
    "Znalezienie tokenów z korpusu w postaci tupli (lemat (downcased), kategoria morfosyntaktyczna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 91.6 ms, sys: 11.1 ms, total: 103 ms\n",
      "Wall time: 27.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokens_per_act = []\n",
    "\n",
    "for law_act in law_acts[:5]:\n",
    "    tokens = []\n",
    "    response_lines = requests.post('http://localhost:9200', law_act.encode('utf-8')).content.decode('utf-8').split('\\n')\n",
    "    for line in response_lines:\n",
    "        line_words = line.split('\\t')\n",
    "        if line_words[0] == '' and len(line_words) >= 2:\n",
    "            tokens.append((line_words[1].lower().strip(), line_words[2].split(':')[0]))\n",
    "    tokens_per_act.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dziennik', 'brev'),\n",
       " ('.', 'interp'),\n",
       " ('ustawa', 'brev'),\n",
       " ('.', 'interp'),\n",
       " ('z', 'prep'),\n",
       " ('1993', 'adj'),\n",
       " ('rok', 'brev'),\n",
       " ('.', 'interp'),\n",
       " ('numer', 'brev'),\n",
       " ('129', 'num')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_per_act[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 3\n",
    "Obliczenie licznika bigramów powstałych z opisanych wyżej tokenów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23 ms, sys: 3.81 ms, total: 26.8 ms\n",
      "Wall time: 26.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bigrams_counter = {}\n",
    "for tokens in tokens_per_act:\n",
    "    bigrams = zip(tokens[:-1], tokens[1:])\n",
    "    for bigram in bigrams:\n",
    "        bigrams_counter[bigram] = bigrams_counter.get(bigram, 0) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 4\n",
    "Odfiltrowanie bigramów zawierających nie litery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 6.14 ms, total: 6.14 ms\n",
      "Wall time: 6.04 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_bigrams_counter = {}\n",
    "for bigram, count in bigrams_counter.items():\n",
    "    if bigram[0][0].isalpha() and bigram[1][0].isalpha():\n",
    "        new_bigrams_counter[bigram] = count\n",
    "bigrams_counter = new_bigrams_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 6\n",
    "Obliczenie LLR dla znalezionych bigramów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8550"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_number_of_bigrams = sum(list(bigrams_counter.values()))\n",
    "total_number_of_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute counter of bigrams starting with a\n",
    "bigrams_starting_with_a_counter = {}\n",
    "for bigram, count in bigrams_counter.items():\n",
    "    a = bigram[0]\n",
    "    bigrams_starting_with_a_counter[a] = bigrams_starting_with_a_counter.get(a, 0) + count\n",
    "    \n",
    "# compute counter of bigrams ending with b\n",
    "bigrams_ending_with_b_counter = {}\n",
    "for bigram, count in bigrams_counter.items():\n",
    "    b = bigram[1]\n",
    "    bigrams_ending_with_b_counter[b] = bigrams_ending_with_b_counter.get(b, 0) + count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H(k):\n",
    "    N = np.sum(k)\n",
    "    return np.sum(k/N * np.log(k/N + (k==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 704 ms, sys: 2 µs, total: 704 ms\n",
      "Wall time: 708 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bigrams_llr = {}\n",
    "for bigram, count in bigrams_counter.items():\n",
    "    a, b = bigram\n",
    "    a_and_b = count\n",
    "    a_without_b = bigrams_starting_with_a_counter[a] - a_and_b\n",
    "    b_but_not_a = bigrams_ending_with_b_counter[b] - a_and_b\n",
    "    neither_a_nor_b = total_number_of_bigrams - bigrams_starting_with_a_counter[a] \\\n",
    "        - bigrams_ending_with_b_counter[b] + a_and_b\n",
    "    \n",
    "    k = np.array([[a_and_b, b_but_not_a], [a_without_b, neither_a_nor_b]])\n",
    "    row_sums = np.array([a_and_b + b_but_not_a, a_without_b + neither_a_nor_b])\n",
    "    col_sums = np.array([a_and_b + a_without_b, b_but_not_a + neither_a_nor_b])\n",
    "    llr = 2 * np.sum(k) * (H(k) - H(row_sums) - H(col_sums))\n",
    "    bigrams_llr[bigram] = llr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((('ustawa', 'subst'), ('z', 'prep')), 104.33712266279504),\n",
       " ((('z', 'prep'), ('dzień', 'subst')), 95.19012075063563),\n",
       " ((('o', 'prep'), ('zmiana', 'subst')), 26.0815334089783),\n",
       " ((('zmiana', 'subst'), ('ustawa', 'subst')), 14.376997774075955),\n",
       " ((('ustawa', 'subst'), ('o', 'prep')), 26.271080105618438),\n",
       " ((('o', 'prep'), ('podatek', 'subst')), 51.49542125103479),\n",
       " ((('podatek', 'subst'), ('od', 'prep')), 88.87138877410224),\n",
       " ((('od', 'prep'), ('towar', 'subst')), 97.4817680254182),\n",
       " ((('towar', 'subst'), ('i', 'conj')), 177.92900056044124),\n",
       " ((('i', 'conj'), ('usługa', 'subst')), 187.30547222383495)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bigrams_llr.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 7\n",
    "Wyznaczenie partycji bigramów zawierających tokeny z tymi samymi kategoriami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions = {}\n",
    "partitions_size = {}\n",
    "\n",
    "for bigram, count in bigrams_counter.items():\n",
    "    partition = (bigram[0][1], bigram[1][1])\n",
    "    partitions[partition] = partitions.get(partition, []) + [(bigram[0][0], bigram[1][0])]\n",
    "    partitions_size[partition] = partitions_size.get(partition, 0) + count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 8\n",
    "Wyznaczenie 10 najliczniejszych partycji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('prep', 'subst'), 1119),\n",
       " (('subst', 'adj'), 817),\n",
       " (('subst', 'subst'), 666),\n",
       " (('subst', 'prep'), 548),\n",
       " (('adj', 'subst'), 524),\n",
       " (('prep', 'brev'), 373),\n",
       " (('conj', 'subst'), 304),\n",
       " (('subst', 'conj'), 291),\n",
       " (('prep', 'adj'), 255),\n",
       " (('ppas', 'prep'), 225)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largest_partitions = sorted(list(partitions_size.items()), key=(lambda x: (-x[1], x[0])))[:10]\n",
    "largest_partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 9\n",
    "Wyznaczenie 5 bigramów z najwyższym LLR reprezentujących każdą z partycji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "categories_representatives = {}\n",
    "sorted_bigrams = sorted(list(bigrams_llr.items()), key=(lambda x: (-x[1], x[0])))\n",
    "for partition, size in largest_partitions:\n",
    "    representatives_found = 0\n",
    "    for bigram, llr in sorted_bigrams:\n",
    "        if bigram[0][1] == partition[0] and bigram[1][1] == partition[1]:\n",
    "            categories_representatives[partition] = categories_representatives.get(partition, []) + [((bigram[0][0], bigram[1][0]), llr)]\n",
    "            representatives_found += 1\n",
    "            if representatives_found == 5:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition: ('prep', 'subst')\n",
      "Representatives:\n",
      "(('z', 'wyjątek'), 148.38829747654103)\n",
      "(('na', 'podstawa'), 147.05413756154223)\n",
      "(('po', 'wyraz'), 143.62085761954634)\n",
      "(('dla', 'dziecko'), 118.3874096133523)\n",
      "(('na', 'cel'), 116.41876512284286)\n",
      "\n",
      "Partition: ('subst', 'adj')\n",
      "Representatives:\n",
      "(('rok', 'podatkowy'), 328.8796640252817)\n",
      "(('podatek', 'dochodowy'), 238.95807076934037)\n",
      "(('urząd', 'skarbowy'), 218.63804117900764)\n",
      "(('rachunek', 'bankowy'), 168.14153388393328)\n",
      "(('działalność', 'gospodarczy'), 127.18188579529782)\n",
      "\n",
      "Partition: ('subst', 'subst')\n",
      "Representatives:\n",
      "(('minister', 'finanse'), 200.23878120202173)\n",
      "(('zwrot', 'różnica'), 172.69666317230906)\n",
      "(('różnica', 'podatek'), 121.41265054404309)\n",
      "(('droga', 'rozporządzenie'), 119.47678407979583)\n",
      "(('sprzedaż', 'towar'), 81.86417754884829)\n",
      "\n",
      "Partition: ('subst', 'prep')\n",
      "Representatives:\n",
      "(('mowa', 'w'), 399.21826588815907)\n",
      "(('ustawa', 'z'), 104.33712266279504)\n",
      "(('podatek', 'od'), 88.87138877410224)\n",
      "(('przepis', 'o'), 71.28160909613385)\n",
      "(('dziecko', 'do'), 49.23905321036882)\n",
      "\n",
      "Partition: ('adj', 'subst')\n",
      "Representatives:\n",
      "(('który', 'mowa'), 589.7668747945598)\n",
      "(('odrębny', 'przepis'), 222.80799536939804)\n",
      "(('przeciętny', 'wynagrodzenie'), 155.13994417611787)\n",
      "(('górny', 'granica'), 107.4748146413471)\n",
      "(('następujący', 'zmiana'), 88.49046381673544)\n",
      "\n",
      "Partition: ('prep', 'brev')\n",
      "Representatives:\n",
      "(('w', 'artykuł'), 561.7289317269402)\n",
      "(('w', 'ustęp'), 423.1748264957714)\n",
      "(('w', 'punkt'), 132.589257755387)\n",
      "(('po', 'ustęp'), 24.08589177656621)\n",
      "(('w', 'litera'), 8.626892872292357)\n",
      "\n",
      "Partition: ('conj', 'subst')\n",
      "Representatives:\n",
      "(('i', 'usługa'), 187.30547222383495)\n",
      "(('i', 'renta'), 50.306527313516504)\n",
      "(('i', 'wpłata'), 33.18446889797986)\n",
      "(('i', 'rozchód'), 26.535097977125712)\n",
      "(('lub', 'nagroda'), 25.232506843330377)\n",
      "\n",
      "Partition: ('subst', 'conj')\n",
      "Representatives:\n",
      "(('towar', 'i'), 177.92900056044124)\n",
      "(('emerytura', 'i'), 60.75032314326951)\n",
      "(('faktura', 'lub'), 48.48656734791373)\n",
      "(('przecinek', 'i'), 43.50403104256308)\n",
      "(('towar', 'lub'), 38.21389530580018)\n",
      "\n",
      "Partition: ('prep', 'adj')\n",
      "Representatives:\n",
      "(('o', 'który'), 407.9324575673354)\n",
      "(('w', 'dany'), 29.735492365541642)\n",
      "(('w', 'który'), 20.13977529837514)\n",
      "(('z', 'odrębny'), 19.099615304045038)\n",
      "(('do', 'bezpłatny'), 17.675425263568044)\n",
      "\n",
      "Partition: ('ppas', 'prep')\n",
      "Representatives:\n",
      "(('określić', 'w'), 376.23202598876867)\n",
      "(('wymienić', 'w'), 115.32041620247509)\n",
      "(('zwolnić', 'od'), 73.42755084807939)\n",
      "(('powiększyć', 'o'), 58.18772801471663)\n",
      "(('stosować', 'w'), 36.56389851760393)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for partition, representatives in categories_representatives.items():\n",
    "    print('Partition:', partition)\n",
    "    print('Representatives:')\n",
    "    for r in representatives:\n",
    "        print(r)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wnioski\n",
    "\n",
    "1. What types of bigrams have been found?\n",
    "\n",
    "what do you mean bro?\n",
    "\n",
    "2. Which of the category-pairs indicate valuable multiword expressions? Do they have anything in common?\n",
    "\n",
    "what do you mean bro?\n",
    "\n",
    "3. Which signal: LLR score or syntactic category is more useful for determining genuine multiword expressions?\n",
    "\n",
    "what do you mean bro?\n",
    "\n",
    "4. Can you describe a different use-case where the morphosyntactic category is useful for resolving a real-world problem?\n",
    "\n",
    "what do you mean bro?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
